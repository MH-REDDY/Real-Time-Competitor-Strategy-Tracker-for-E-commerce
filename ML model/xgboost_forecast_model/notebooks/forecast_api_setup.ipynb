{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa220a3c",
   "metadata": {},
   "source": [
    "# üöÄ Price Forecast API Setup\n",
    "\n",
    "This notebook:\n",
    "1. Extracts unique brands and models from `expanded_prices_10k.xlsx`\n",
    "2. Exports them to JSON for the React frontend\n",
    "3. Creates a Flask API that uses the trained XGBoost model for 30-day forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bf790",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "\n",
    "Run this cell first to install all dependencies needed for the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "014f3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn[standard] openpyxl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad5e0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix environment compatibility for FastAPI/Pydantic\n",
    "!pip install -U typing_extensions pydantic annotated-types -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa542a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.0 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.3 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.20.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Force upgrade with explicit versions for compatibility\n",
    "!python -m pip install -U typing_extensions==4.12.2 pydantic==2.10.4 fastapi==0.115.4 annotated-types==0.7.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ad13147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: typing_extensions 4.12.2\n",
      "Uninstalling typing_extensions-4.12.2:\n",
      "  Successfully uninstalled typing_extensions-4.12.2\n",
      "typing_extensions path: c:\\Users\\kvpra\\OneDrive\\Desktop\\sample_project_1\\myenv1\\lib\\site-packages\\typing_extensions.py\n",
      "Has Sentinel: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.0 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.3 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.20.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Hard reset typing_extensions to a compatible version\n",
    "!python -m pip uninstall -y typing_extensions\n",
    "!python -m pip install typing_extensions==4.12.2 -q\n",
    "\n",
    "import typing_extensions as te\n",
    "print('typing_extensions path:', getattr(te, '__file__', 'unknown'))\n",
    "print('Has Sentinel:', hasattr(te, 'Sentinel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b254b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reload -> Has Sentinel: False\n"
     ]
    }
   ],
   "source": [
    "# Try reloading typing_extensions in current kernel\n",
    "import importlib, typing_extensions as te\n",
    "te = importlib.reload(te)\n",
    "print('After reload -> Has Sentinel:', hasattr(te, 'Sentinel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa53731",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "071cb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading expanded_prices_10k.xlsx...\n",
      "‚úÖ Loaded 11000 rows\n",
      "\n",
      "Columns: ['product_id', 'Brand', 'Model', 'Category', 'Date', 'Time', 'SaleEvent', 'Price', 'DiscountPercentage']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>SaleEvent</th>\n",
       "      <th>Price</th>\n",
       "      <th>DiscountPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0004</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>Buds Z2</td>\n",
       "      <td>True Wireless Earbuds</td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0004</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>Buds Z2</td>\n",
       "      <td>True Wireless Earbuds</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>16:11:00</td>\n",
       "      <td>No Sale</td>\n",
       "      <td>5055.58</td>\n",
       "      <td>-1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0006</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>HD 450SE</td>\n",
       "      <td>On-Ear Headphones</td>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>8954.93</td>\n",
       "      <td>10.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0001</td>\n",
       "      <td>Bose</td>\n",
       "      <td>QuietComfort Ultra</td>\n",
       "      <td>On-Ear Headphones</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>14:44:00</td>\n",
       "      <td>No Sale</td>\n",
       "      <td>39447.29</td>\n",
       "      <td>-1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0004</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>Buds Z2</td>\n",
       "      <td>True Wireless Earbuds</td>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>17:10:00</td>\n",
       "      <td>No Sale</td>\n",
       "      <td>5036.52</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id       Brand               Model               Category  \\\n",
       "0      P0004     OnePlus             Buds Z2  True Wireless Earbuds   \n",
       "1      P0004     OnePlus             Buds Z2  True Wireless Earbuds   \n",
       "2      P0006  Sennheiser            HD 450SE      On-Ear Headphones   \n",
       "3      P0001        Bose  QuietComfort Ultra      On-Ear Headphones   \n",
       "4      P0004     OnePlus             Buds Z2  True Wireless Earbuds   \n",
       "\n",
       "         Date      Time          SaleEvent     Price  DiscountPercentage  \n",
       "0  2024-06-02  09:00:00                NaN   4999.00                0.00  \n",
       "1  2024-03-28  16:11:00            No Sale   5055.58               -1.13  \n",
       "2  2025-09-18  09:35:00  Republic Day Sale   8954.93               10.36  \n",
       "3  2023-08-08  14:44:00            No Sale  39447.29               -1.41  \n",
       "4  2024-03-19  17:10:00            No Sale   5036.52               -0.75  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Excel data\n",
    "print(\"üìä Loading expanded_prices_10k.xlsx...\")\n",
    "df = pd.read_excel('expanded_prices_10k.xlsx')\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e7e58ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è  Coerced Date column to datetime. Min: 2023-01-01 Max: 2025-10-25\n"
     ]
    }
   ],
   "source": [
    "# Ensure Date column is datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "# Drop any rows with invalid dates (if any)\n",
    "df = df.dropna(subset=['Date']).copy()\n",
    "print('üóìÔ∏è  Coerced Date column to datetime. Min:', df['Date'].min().date(), 'Max:', df['Date'].max().date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0660c488",
   "metadata": {},
   "source": [
    "## Step 2: Extract Unique Brands and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d9523a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì± Found 6 unique brands:\n",
      "['Bose', 'JBL', 'OnePlus', 'Sennheiser', 'Sony', 'boAt']\n",
      "\n",
      "Bose: 1 models\n",
      "  Sample: ['QuietComfort Ultra']\n",
      "\n",
      "JBL: 2 models\n",
      "  Sample: ['Flip 6', 'Go 3']\n",
      "\n",
      "OnePlus: 1 models\n",
      "  Sample: ['Buds Z2']\n",
      "\n",
      "Sennheiser: 2 models\n",
      "  Sample: ['CX 80S', 'HD 450SE']\n",
      "\n",
      "Sony: 3 models\n",
      "  Sample: ['HT-S20R', 'WF-1000XM5', 'WH-CH520']\n",
      "\n",
      "boAt: 3 models\n",
      "  Sample: ['Aavante Bar 1160', 'Airdopes 141', 'Rockerz 450']\n",
      "\n",
      "‚úÖ Exported brands_models.json for React frontend\n"
     ]
    }
   ],
   "source": [
    "# Get unique brands\n",
    "brands = sorted(df['Brand'].unique().tolist())\n",
    "print(f\"üì± Found {len(brands)} unique brands:\")\n",
    "print(brands)\n",
    "\n",
    "# Get models for each brand\n",
    "models_by_brand = {}\n",
    "for brand in brands:\n",
    "    models = sorted(df[df['Brand'] == brand]['Model'].unique().tolist())\n",
    "    models_by_brand[brand] = models\n",
    "    print(f\"\\n{brand}: {len(models)} models\")\n",
    "    print(f\"  Sample: {models[:3]}\")\n",
    "\n",
    "# Export to JSON for React frontend\n",
    "brands_models_data = {\n",
    "    'brands': brands,\n",
    "    'modelsByBrand': models_by_brand\n",
    "}\n",
    "\n",
    "with open('brands_models.json', 'w') as f:\n",
    "    json.dump(brands_models_data, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Exported brands_models.json for React frontend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db9305",
   "metadata": {},
   "source": [
    "## Step 3: Load XGBoost Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c26a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for required ML artifacts...\n",
      " - xgboost_model_tuned.json: ‚úÖ found\n",
      " - label_encoders.pkl: ‚úÖ found\n",
      " - feature_columns.json: ‚úÖ found\n",
      "\n",
      "‚úÖ All required artifacts are present. Proceeding to load the model...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'xgboost_model_tuned.json',\n",
    "    'label_encoders.pkl',\n",
    "    'feature_columns.json'\n",
    "]\n",
    "\n",
    "print('üîç Checking for required ML artifacts...')\n",
    "missing = [f for f in required_files if not os.path.exists(f)]\n",
    "for f in required_files:\n",
    "    print(f\" - {f}: {'‚úÖ found' if f not in missing else '‚ùå missing'}\")\n",
    "\n",
    "if missing:\n",
    "    print('\\n‚ùó One or more required files are missing:')\n",
    "    for f in missing:\n",
    "        print(f\"   ‚Ä¢ {f}\")\n",
    "    print('\\nFix options:')\n",
    "    print('  1) Open xgboost_model.ipynb and Run All to save artifacts into this same folder')\n",
    "    print('  2) If you have them elsewhere, copy the files here')\n",
    "    raise FileNotFoundError('Missing ML artifacts: ' + ', '.join(missing))\n",
    "\n",
    "print('\\n‚úÖ All required artifacts are present. Proceeding to load the model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83a95ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading XGBoost model...\n",
      "‚úÖ Model loaded successfully\n",
      "\n",
      "üì¶ Loading label encoders...\n",
      "‚úÖ Loaded 6 label encoders\n",
      "\n",
      "üìã Loading feature columns...\n",
      "‚úÖ Loaded 27 feature columns\n",
      "\n",
      "üéØ Model ready for forecasting!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained XGBoost model\n",
    "print(\"ü§ñ Loading XGBoost model...\")\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model('xgboost_model_tuned.json')\n",
    "print(\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Load label encoders\n",
    "print(\"\\nüì¶ Loading label encoders...\")\n",
    "with open('label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "print(f\"‚úÖ Loaded {len(label_encoders)} label encoders\")\n",
    "\n",
    "# Load feature columns\n",
    "print(\"\\nüìã Loading feature columns...\")\n",
    "with open('feature_columns.json', 'r') as f:\n",
    "    feature_cols = json.load(f)\n",
    "print(f\"‚úÖ Loaded {len(feature_cols)} feature columns\")\n",
    "\n",
    "print(\"\\nüéØ Model ready for forecasting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c3dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Feature columns (ordered):\n",
      "['product_id', 'Brand', 'Model', 'Category', 'Time', 'SaleEvent', 'HasSaleEvent', 'year', 'month', 'day', 'dayofweek', 'quarter', 'week_of_year', 'is_weekend', 'is_month_start', 'is_month_end', 'days_in_month', 'DiscountPercentage_lag_1', 'DiscountPercentage_lag_2', 'DiscountPercentage_lag_3', 'DiscountPercentage_lag_7', 'DiscountPercentage_lag_14', 'DiscountPercentage_lag_30', 'DiscountPercentage_rolling_mean_7', 'DiscountPercentage_rolling_std_7', 'DiscountPercentage_rolling_mean_30', 'DiscountPercentage_rolling_std_30']\n",
      "\n",
      "üîë Label encoders available: ['Brand', 'Model', 'Category', 'product_id', 'SaleEvent', 'Time']\n"
     ]
    }
   ],
   "source": [
    "print('\\nüîé Feature columns (ordered):')\n",
    "print(feature_cols)\n",
    "print('\\nüîë Label encoders available:', list(label_encoders.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d37c84",
   "metadata": {},
   "source": [
    "## Step 4: Create Forecast Function\n",
    "\n",
    "This function will:\n",
    "1. Filter data for specific brand and model\n",
    "2. Get last 60 days of historical data\n",
    "3. Use XGBoost model to predict next 30 days\n",
    "4. Return both historical and forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "449f3536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing forecast for: Bose - QuietComfort Ultra\n",
      "\n",
      "‚úÖ Generated 60 historical points\n",
      "‚úÖ Generated 30 forecast points\n"
     ]
    }
   ],
   "source": [
    "def generate_forecast(brand, model_name, days=30):\n",
    "    \"\"\"\n",
    "    Generate price and discount forecast for a specific brand and model using the trained XGBoost model.\n",
    "\n",
    "    Returns a dict with keys: brand, model, historical, forecast.\n",
    "    - historical: last 60 days from the dataset with fields {date, price, discount}\n",
    "    - forecast: next `days` days with fields {date, price, discount}\n",
    "    \"\"\"\n",
    "    # Filter data for specific brand and model\n",
    "    filtered_df = df[(df['Brand'] == brand) & (df['Model'] == model_name)].copy()\n",
    "    if filtered_df.empty:\n",
    "        return {\"error\": f\"No data found for {brand} - {model_name}\"}\n",
    "\n",
    "    # Sort by date\n",
    "    filtered_df = filtered_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Use most frequent categorical values for constant fields\n",
    "    top_product_id = filtered_df['product_id'].mode().iat[0]\n",
    "    top_category = filtered_df['Category'].mode().iat[0]\n",
    "    top_time = filtered_df['Time'].mode().iat[0]\n",
    "\n",
    "    # Prepare historical data (last 60 days)\n",
    "    historical_data = filtered_df.tail(60)\n",
    "    historical = [\n",
    "        {\n",
    "            'date': d.strftime('%Y-%m-%d'),\n",
    "            'price': float(p),\n",
    "            'discount': float(dc)\n",
    "        }\n",
    "        for d, p, dc in zip(historical_data['Date'], historical_data['Price'], historical_data['DiscountPercentage'])\n",
    "    ]\n",
    "\n",
    "    # For feature engineering of lags/rolling, maintain series of discounts\n",
    "    discount_series = historical_data['DiscountPercentage'].tolist()\n",
    "\n",
    "    # Helper to encode with fallback for unseen labels\n",
    "    def encode_safe(le, value, fallback=None):\n",
    "        classes = set(le.classes_.tolist()) if hasattr(le, 'classes_') else set()\n",
    "        if value in classes:\n",
    "            return int(le.transform([value])[0])\n",
    "        fb = fallback if fallback is not None else list(classes)[0] if classes else value\n",
    "        return int(le.transform([fb])[0])\n",
    "\n",
    "    # Encoders\n",
    "    enc_brand = label_encoders['Brand']\n",
    "    enc_model = label_encoders['Model']\n",
    "    enc_category = label_encoders['Category']\n",
    "    enc_product = label_encoders['product_id']\n",
    "    enc_time = label_encoders['Time']\n",
    "    enc_sale = label_encoders['SaleEvent']\n",
    "\n",
    "    # Encoded base values (with safe fallback)\n",
    "    brand_encoded = encode_safe(enc_brand, brand)\n",
    "    model_encoded = encode_safe(enc_model, model_name)\n",
    "    category_encoded = encode_safe(enc_category, top_category)\n",
    "    product_encoded = encode_safe(enc_product, top_product_id)\n",
    "    time_encoded = encode_safe(enc_time, top_time)\n",
    "\n",
    "    # Choose sale event for forecast\n",
    "    sale_event_value = 'No Sale' if hasattr(enc_sale, 'classes_') and ('No Sale' in enc_sale.classes_) else (filtered_df['SaleEvent'].mode().iat[0] if not filtered_df['SaleEvent'].isna().all() else 'No Sale')\n",
    "    sale_event_encoded = encode_safe(enc_sale, sale_event_value)\n",
    "\n",
    "    # Price trend estimate (simple): mean pct change over last 14 days\n",
    "    price_hist = historical_data['Price'].astype(float)\n",
    "    recent_pct_change = price_hist.pct_change().tail(14).mean()\n",
    "    if pd.isna(recent_pct_change):\n",
    "        recent_pct_change = 0.0\n",
    "\n",
    "    last_price = float(price_hist.iloc[-1])\n",
    "    last_discount = float(historical_data['DiscountPercentage'].iloc[-1])\n",
    "\n",
    "    forecast_data = []\n",
    "    last_date = historical_data['Date'].max()\n",
    "\n",
    "    for i in range(days):\n",
    "        forecast_date = last_date + pd.Timedelta(days=i + 1)\n",
    "\n",
    "        # Temporal features\n",
    "        year = forecast_date.year\n",
    "        month = forecast_date.month\n",
    "        day = forecast_date.day\n",
    "        dayofweek = forecast_date.dayofweek\n",
    "        quarter = (month - 1) // 3 + 1\n",
    "        week_of_year = int(forecast_date.strftime('%U'))\n",
    "        is_weekend = 1 if dayofweek >= 5 else 0\n",
    "        is_month_start = 1 if day == 1 else 0\n",
    "        is_month_end = 1 if (forecast_date + pd.Timedelta(days=1)).month != month else 0\n",
    "        days_in_month = int(pd.Period(forecast_date, freq='M').days_in_month)\n",
    "\n",
    "        # Lag features for DiscountPercentage\n",
    "        def lag(n):\n",
    "            if len(discount_series) >= n:\n",
    "                return float(discount_series[-n])\n",
    "            return float(discount_series[-1])\n",
    "\n",
    "        # Rolling stats helpers\n",
    "        def rolling_mean(n):\n",
    "            arr = discount_series[-n:] if len(discount_series) >= n else discount_series\n",
    "            return float(pd.Series(arr).mean())\n",
    "\n",
    "        def rolling_std(n):\n",
    "            arr = discount_series[-n:] if len(discount_series) >= n else discount_series\n",
    "            val = float(pd.Series(arr).std(ddof=0))\n",
    "            return 0.0 if pd.isna(val) else val\n",
    "\n",
    "        # Assemble feature row matching training columns exactly\n",
    "        feat = {\n",
    "            'product_id': product_encoded,\n",
    "            'Brand': brand_encoded,\n",
    "            'Model': model_encoded,\n",
    "            'Category': category_encoded,\n",
    "            'Time': time_encoded,\n",
    "            'SaleEvent': sale_event_encoded,\n",
    "            'HasSaleEvent': 0 if (isinstance(sale_event_value, str) and sale_event_value.lower() in ['no sale', 'nan']) else 1,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'dayofweek': dayofweek,\n",
    "            'quarter': quarter,\n",
    "            'week_of_year': week_of_year,\n",
    "            'is_weekend': is_weekend,\n",
    "            'is_month_start': is_month_start,\n",
    "            'is_month_end': is_month_end,\n",
    "            'days_in_month': days_in_month,\n",
    "            'DiscountPercentage_lag_1': lag(1),\n",
    "            'DiscountPercentage_lag_2': lag(2),\n",
    "            'DiscountPercentage_lag_3': lag(3),\n",
    "            'DiscountPercentage_lag_7': lag(7),\n",
    "            'DiscountPercentage_lag_14': lag(14),\n",
    "            'DiscountPercentage_lag_30': lag(30),\n",
    "            'DiscountPercentage_rolling_mean_7': rolling_mean(7),\n",
    "            'DiscountPercentage_rolling_std_7': rolling_std(7),\n",
    "            'DiscountPercentage_rolling_mean_30': rolling_mean(30),\n",
    "            'DiscountPercentage_rolling_std_30': rolling_std(30),\n",
    "        }\n",
    "\n",
    "        # Ensure correct column order and fill any missing required columns defensively\n",
    "        row_df = pd.DataFrame([{col: feat.get(col, 0) for col in feature_cols}])\n",
    "\n",
    "        # Predict discount using Booster\n",
    "        dmat = xgb.DMatrix(row_df)\n",
    "        pred_discount = float(xgb_model.predict(dmat)[0])\n",
    "\n",
    "        # Clamp to reasonable range (-50% to 90%) to avoid outliers\n",
    "        pred_discount = max(-50.0, min(90.0, pred_discount))\n",
    "\n",
    "        # Update series for future lags/rolling\n",
    "        discount_series.append(pred_discount)\n",
    "\n",
    "        # Simple price projection: apply recent trend and adjust by discount delta\n",
    "        discount_delta = (pred_discount - last_discount) / 100.0\n",
    "        price_trend = recent_pct_change if not pd.isna(recent_pct_change) else 0.0\n",
    "        adjusted = last_price * (1.0 + price_trend - 0.2 * discount_delta)\n",
    "        last_price = float(max(1.0, adjusted))\n",
    "        last_discount = pred_discount\n",
    "\n",
    "        forecast_data.append({\n",
    "            'date': forecast_date.strftime('%Y-%m-%d'),\n",
    "            'price': round(last_price, 2),\n",
    "            'discount': round(pred_discount, 2)\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'brand': brand,\n",
    "        'model': model_name,\n",
    "        'historical': historical,\n",
    "        'forecast': forecast_data\n",
    "    }\n",
    "\n",
    "# Test the function with first brand/model\n",
    "test_brand = brands[0]\n",
    "test_model = models_by_brand[test_brand][0]\n",
    "print(f\"üß™ Testing forecast for: {test_brand} - {test_model}\")\n",
    "result = generate_forecast(test_brand, test_model)\n",
    "print(f\"\\n‚úÖ Generated {len(result['historical'])} historical points\")\n",
    "print(f\"‚úÖ Generated {len(result['forecast'])} forecast points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7377d",
   "metadata": {},
   "source": [
    "## Step 5: Create FastAPI Application\n",
    "\n",
    "This API will serve forecast data to the React frontend. FastAPI provides:\n",
    "- Automatic interactive documentation at `/docs`\n",
    "- Better performance than Flask\n",
    "- Built-in request/response validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79123d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FastAPI application created!\n",
      "\n",
      "üì° Available endpoints:\n",
      "   POST /api/forecast - Generate forecast for brand/model\n",
      "   GET  /api/brands - Get all brands and models\n",
      "   GET  /health - Health check\n",
      "   GET  /docs - Interactive API documentation\n",
      "   GET  /redoc - Alternative API documentation\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Price Forecast API\",\n",
    "    description=\"ML-powered price and discount forecasting using XGBoost\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Enable CORS for React frontend\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # In production, replace with specific origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Request/Response models\n",
    "class ForecastRequest(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "\n",
    "class DataPoint(BaseModel):\n",
    "    date: str\n",
    "    price: float\n",
    "    discount: float\n",
    "\n",
    "class ForecastResponse(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    historical: List[DataPoint]\n",
    "    forecast: List[DataPoint]\n",
    "\n",
    "class BrandsResponse(BaseModel):\n",
    "    brands: List[str]\n",
    "    modelsByBrand: Dict[str, List[str]]\n",
    "\n",
    "@app.post(\"/api/forecast\", response_model=ForecastResponse)\n",
    "async def forecast(request: ForecastRequest):\n",
    "    \"\"\"\n",
    "    Generate 30-day price and discount forecast for a specific brand and model.\n",
    "    \n",
    "    - **brand**: Brand name (e.g., \"Apple\")\n",
    "    - **model**: Model name (e.g., \"iPhone 13\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = generate_forecast(request.brand, request.model)\n",
    "        \n",
    "        if 'error' in result:\n",
    "            raise HTTPException(status_code=404, detail=result['error'])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/api/brands\", response_model=BrandsResponse)\n",
    "async def get_brands():\n",
    "    \"\"\"Get all available brands and their models\"\"\"\n",
    "    try:\n",
    "        return {\n",
    "            'brands': brands,\n",
    "            'modelsByBrand': models_by_brand\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"ok\", \"message\": \"Forecast API is running\"}\n",
    "\n",
    "print(\"‚úÖ FastAPI application created!\")\n",
    "print(\"\\nüì° Available endpoints:\")\n",
    "print(\"   POST /api/forecast - Generate forecast for brand/model\")\n",
    "print(\"   GET  /api/brands - Get all brands and models\")\n",
    "print(\"   GET  /health - Health check\")\n",
    "print(\"   GET  /docs - Interactive API documentation\")\n",
    "print(\"   GET  /redoc - Alternative API documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a871450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typing_extensions path: c:\\Users\\kvpra\\OneDrive\\Desktop\\sample_project_1\\myenv1\\lib\\site-packages\\typing_extensions.py\n",
      "typing_extensions version attr: unknown\n",
      "Has Sentinel: False\n",
      "Python: 3.9.20 (main, Oct  3 2024, 07:38:01) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import typing_extensions as te\n",
    "import importlib, sys\n",
    "print('typing_extensions path:', getattr(te, '__file__', 'unknown'))\n",
    "print('typing_extensions version attr:', getattr(te, '__version__', 'unknown'))\n",
    "print('Has Sentinel:', hasattr(te, 'Sentinel'))\n",
    "print('Python:', sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4787aa",
   "metadata": {},
   "source": [
    "## Step 6: Run the FastAPI Server\n",
    "\n",
    "Execute the cell below to start the FastAPI server on port 5000.\n",
    "\n",
    "**Note:** \n",
    "- The server will run in this notebook and block further execution\n",
    "- To stop it, interrupt the kernel\n",
    "- Visit `http://localhost:5000/docs` for interactive API documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431851e7",
   "metadata": {},
   "source": [
    "## Step 6B: Alternative (Flask API Fallback)\n",
    "\n",
    "If FastAPI import fails due to environment packages, you can run this Flask fallback without extra dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05427674",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from flask import Flask, request, jsonify\n",
    "    from flask_cors import CORS\n",
    "except ImportError:\n",
    "    !python -m pip install flask flask-cors -q\n",
    "    from flask import Flask, request, jsonify\n",
    "    from flask_cors import CORS\n",
    "\n",
    "flask_app = Flask(__name__)\n",
    "CORS(flask_app)\n",
    "\n",
    "@flask_app.route('/api/forecast', methods=['POST'])\n",
    "def flask_forecast():\n",
    "    data = request.json or {}\n",
    "    brand = data.get('brand')\n",
    "    model = data.get('model')\n",
    "    if not brand or not model:\n",
    "        return jsonify({'error': 'Brand and model are required'}), 400\n",
    "    res = generate_forecast(brand, model)\n",
    "    if 'error' in res:\n",
    "        return jsonify(res), 404\n",
    "    return jsonify(res), 200\n",
    "\n",
    "@flask_app.route('/api/brands', methods=['GET'])\n",
    "def flask_brands():\n",
    "    return jsonify({'brands': brands, 'modelsByBrand': models_by_brand}), 200\n",
    "\n",
    "@flask_app.route('/health', methods=['GET'])\n",
    "def flask_health():\n",
    "    return jsonify({'status': 'ok', 'framework': 'flask'}), 200\n",
    "\n",
    "print('‚úÖ Flask fallback API is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e48250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Flask fallback server\n",
    "if __name__ == '__main__':\n",
    "    print('üöÄ Starting Flask fallback on http://localhost:5000 ...')\n",
    "    flask_app.run(host='0.0.0.0', port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "378c5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting FastAPI server...\n",
      "üìç Server will be available at: http://localhost:5000\n",
      "üìö API Documentation at: http://localhost:5000/docs\n",
      "‚ö†Ô∏è  To stop the server, interrupt the kernel (Ctrl+C or Interrupt button)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è  To stop the server, interrupt the kernel (Ctrl+C or Interrupt button)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kvpra\\OneDrive\\Desktop\\sample_project_1\\myenv1\\lib\\site-packages\\uvicorn\\main.py:593\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, timeout_worker_healthcheck, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    591\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 593\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kvpra\\OneDrive\\Desktop\\sample_project_1\\myenv1\\lib\\site-packages\\uvicorn\\server.py:67\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loop_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kvpra\\OneDrive\\Desktop\\sample_project_1\\myenv1\\lib\\site-packages\\uvicorn\\_compat.py:46\u001b[0m, in \u001b[0;36masyncio_run\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"üöÄ Starting FastAPI server...\")\n",
    "    print(\"üìç Server will be available at: http://localhost:5000\")\n",
    "    print(\"üìö API Documentation at: http://localhost:5000/docs\")\n",
    "    print(\"‚ö†Ô∏è  To stop the server, interrupt the kernel (Ctrl+C or Interrupt button)\")\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
